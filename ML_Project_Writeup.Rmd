---
title: "Coursera ML Project Writeup"
author: "MM"
date: "August 22, 2015"
output: html_document
---

## Background

In this project, for the Coursera class on *Practical Machine Learning*, data is used from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The goal of this project is to predict how well the participants perform the barbell lifts.  More information is available from the website here: <http://groupware.les.inf.puc-rio.br/har> (see the section on the Weight Lifting Exercise Dataset). 


## Choosing, Building and Implementing a Model

### Prediction Outcome Variable

In the training set, the [**classe**] variable represents how well each participant performs the barbell lifts, and this is what we'll be predicting in testing set.  The [**classe**] variable is defined as:

- **A**: The correct execution of the exercise
- **B**: Throwing the elbows to the front
- **C**: Lifting the dumbbell only halfway
- **D**: Lowering the dumbbell only halfway
- **E**: Throwing the hips to the front

### Selection of Predictor Variables

We begin by splitting the dataset into training and testing sets so that we can perform cross validation and calculate an out of sample error rate on our model.

```{r, results='hide'}
## Working directory must be set
## Load package dependencies
library(lattice)
library(ggplot2)
library(caret)
library(randomForest)

## Load the dataset
data <- read.csv("pml-training.csv")

## Split the dataset into training and testing sets
inTrain <- createDataPartition(y=data$classe, p=.6, list=FALSE)
training <- data[inTrain, ]
testing <- data[-inTrain, ]
```

By examining the structure of the training set, we notice a high proportion of `NA` values in a high number of columns.  The prediction model will exclude columns that have greater than 90% of its values as `NA`.  We also remove variables that are not of a numeric class under the assumption that non-numeric variables will not provide much predictive value as it relates to accelerometer measurements.

```{r}
## Define function to measure proportion of NA values in a given column
colNA <- function(x) {sum(is.na(x))/length(x)}

## Subset the training set for columns with less than 90% NA values
trainsub <- training[ , sapply(training, colNA)<.9]

## Remove other metadata
trainsub <- trainsub[ , 8:93]

## Remove other non-numeric variables
trainsub <- trainsub[ , !grepl("kurtosis", names(trainsub)) &
                              !grepl("skewness", names(trainsub)) &
                              !grepl("min", names(trainsub)) &
                              !grepl("max", names(trainsub)) &
                              !grepl("amplitude", names(trainsub))
                      ]
```

### Training a Machine Learning Algorithm

Given the complexity of the remaining measurements, we've elected to apply a **Random Forest** model to determine variable importance automatically.  Due to processing time constraints, we've limited the number of trees to 100.  We will use **5-fold cross validation** when applying the algorithm. 

```{r}
## Train the model on the testing set
modFit <- train(classe~., 
                data=trainsub, 
                method="rf", 
                trControl=trainControl(method="cv", number=5), 
                ntree=100
                )

print(modFit)
```

### Testing the Accuracy of the Model

Next, we'll apply the model to the testing set and measure its accuracy.  We must be sure to apply the same manipulations to the testing set that we applied to the training set.

```{r}
## Subset the training set in the same way that was done with the training set
testsub <- testing[ , names(trainsub)]

## Remove the classe variable for prediction
testsub <- testsub[ , -53]

## Apply model to testing set
pred <- predict(modFit, newdata=testsub)

## Calculate accuracy
confusionMatrix(testing$classe, pred)

accuracy <- confusionMatrix(testing$classe, pred)$overall[1]
oos <- 1 - accuracy
```

From the output above we are acheiving high accuracy: `r accuracy`. We see an **out of sample error rate** of `r oos`.

```{r}
modFit$finalModel
```


## Conclusion

**Model Selection**: Of the machine learning algorithms were applied, the Random Forest model achieved the highest accuracy when classifying how well dumbell lifts were performed based on measured accelerometer data.

**Cross Validation**: The model used 5-fold cross validation to ensure robust accuracy.  Similar accuracies were observed in each fold.  

**Out of Sample Error**: A separate testing set was cut from the training data to calculate an out of sample error rate.  The model was not trained on this set.

**Quiz Submission Preview**: Results for the 20 test cases under the Programming Assignment portion of this project can be viewed here:

```{r}
## Read the programming assignment test set
part2test <- read.csv("pml-testing.csv")

## Run the prediction model
predict(modFit, newdata=part2test[ , names(testsub)])
```

## Appendix

Variable Importance in the Random Forest Model

```{r}
varImp(modFit)
```

Plot of the two most important variables above in the training set

```{r}
qplot(pitch_forearm, roll_belt, data=trainsub, color=classe)
```


